from ultralytics import YOLO
import cv2 

class dogmonitor:
    def __init__(self):
        self.model = YOLO('yolo11x.pt')
        self.traffic_classes = {
            16: 'dog'
        }
        self.stats = {'total_detections': 0, 'by_class': {}}
    
    def analyze_frame(self, frame):
        # model() ëŒ€ì‹  model.track()ì„ ì‚¬ìš©í•˜ì—¬ ê°ì²´ ì¶”ì  í™œì„±í™”
        # persist=True: ì´ì „ í”„ë ˆì„ì˜ ì¶”ì  ì •ë³´ë¥¼ ìœ ì§€
        # conf=0.3: ì‹ ë¢°ë„ ì„ê³„ê°’ì„ ë‚®ì¶° ë” ë§ì€ ê°ì²´ë¥¼ ì¶”ì í•˜ë„ë¡ í•¨
        results = self.model.track(
            frame, 
            classes=list(self.traffic_classes.keys()), 
            conf=0.3, 
            persist=True, 
            verbose=False
        )
        
        frame_stats = {'dogs': 0}
        
        if results[0].boxes is not None:
            # ì¶”ì  IDë¥¼ í¬í•¨í•œ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì²˜ë¦¬
            for box in results[0].boxes:
                class_id = int(box.cls[0])
                class_name = self.traffic_classes[class_id]
                
                if class_id == 16:
                    frame_stats['dogs'] += 1
                
                self.stats['by_class'][class_name] = \
                    self.stats['by_class'].get(class_name, 0) + 1
            
            # ì—¬ê¸°ì„œ total_detectionsëŠ” ê° í”„ë ˆì„ì—ì„œ ì¸ì‹ëœ ê°ì²´ì˜ ì´í•©
            self.stats['total_detections'] += len(results[0].boxes)
        
        return results[0].plot(), frame_stats
    
    def run_video_monitoring(self, video_path):
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"ì˜¤ë¥˜: ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {video_path}")
            return
            
        print(f"ğŸ¶ ë¹„ë””ì˜¤ íŒŒì¼ '{video_path}' ë¶„ì„ ì‹œì‘! që¡œ ì¢…ë£Œ")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            annotated_frame_full, frame_stats = self.analyze_frame(frame)
            
            height, width = annotated_frame_full.shape[:2]
            resized_annotated_frame = cv2.resize(annotated_frame_full, (width // 2, height // 2))

            y = 30
            cv2.putText(resized_annotated_frame, f"Dogs: {frame_stats['dogs']}", 
                        (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            y += 30
            cv2.putText(resized_annotated_frame, f"Total Detected: {self.stats['total_detections']}", 
                        (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
            
            cv2.imshow('Dog Monitoring System', resized_annotated_frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
        self.show_final_stats()
    
    def show_final_stats(self):
        print("\nğŸ“Š ìµœì¢… í†µê³„:")
        print(f"ì´ ê²€ì¶œ íšŸìˆ˜: {self.stats['total_detections']}")
        print("í´ë˜ìŠ¤ë³„ ê²€ì¶œ í˜„í™©:")
        for class_name, count in self.stats['by_class'].items():
            print(f"  {class_name}: {count}íšŒ")

# ì‹œìŠ¤í…œ ì‹¤í–‰
monitor = dogmonitor()
video_file_path = '../img/Idiot_dogs.mp4'
monitor.run_video_monitoring(video_file_path)